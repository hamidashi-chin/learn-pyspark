# PySparkでストリーミング処理

この講座わかりにくかったので途中でやめました！

## 動画で使用している資料
https://github.com/yk-st/pyspark_streaming

## 環境構築

### リソース
https://github.com/yk-st/pyspark_settings

## Kafka(メッセージキュー)基礎知識

Apache Kafka, AWS Kinesis

### Apache Kafkaの特徴
LinkedInが開発し、オープンソースとして公開されている分散型メッセージングシステム

#### 特徴
- 自由にカスタマイズ可能。オンプレやクラウドに自由にデプロイ可能。
- データはトピック内に格納され、指定された保持期間や容量までデータを保存可能。
- 高スループット：大量データの処理に優れる。
- パーティショニング：トピックを複数のパーティションに分割し、並列処理を実現。

#### ユースケース
- ログの集約・リアルタイム分析
- データパイプラインの構築（例：ログの収集→データレイク送信）
- マイクロサービス間のメッセージ通信

### AWS Kinesisの特徴
Amazonが提供するフルマネージドのデータストリーミングサービス

#### 特徴
- マネージドサービス：インフラ管理不要（Kafkaのようにクラスタ管理不要）
- ３つの主要サービス：
  - Kinesis Data Streams：Kafkaのようにリアルタイムデータストリーミング
  - Kinesis Data Firehose：データを自動でS3やRedshiftに配信
  - Kinesis Data Analytics：SQLライクにデータストリームをリアルタイム解析
- シャード(Shard)：Kafkaのパーティションに相当するもので、シャード単位で並列処理
- 保存期間：デフォルト24時間(最大365日まで拡張可能)

#### ユースケース
- IoTデバイスのデータ収集
- Webサイトのリアルタイムアクティビティモニタリング
- ログのリアルタイム収集とS3への保存

### Apache KafkaとAWS Kinesisの違い

|特徴 | Apache Kafka | AWS Kinesis |
| --- | --- | --- |
|提供形態 | オープンソース (自前管理) | マネージドサービス (AWS管理) |
|インフラ管理 | 自分で管理 (クラスタ構築) | AWSが管理 |
|データ保持期間 | 無制限（設定次第） | 最大365日 (デフォルト24時間) |
|スケーリング | パーティション単位の管理 | シャード単位の管理 |
|コスト構造 | インフラ+ストレージコスト | 従量課金制 (シャード数に依存) |
|ユースケース | 大規模データパイプライン | IoTやログ収集、分析ツール連携 |
|学習コスト | 高め (Kafkaの知識が必要) | 低め (AWSコンソールで完結) |

### 関係性と選択ポイント

- 似ている点: 両方ともリアルタイムのストリーミングデータを扱うためのプラットフォーム。
- 主な違い:
  - Kafka: 自由度が高くカスタマイズ性が高いが、管理コストも高い。
  - Kinesis: AWS環境に最適化されており、管理負担が少ないが、AWS依存。
- 使い分けの目安:
  - Kafka → 自前で制御が必要、大規模データパイプライン構築。
  - Kinesis → AWSにフル依存、シンプルに使いたい場合。
- 結論
  - Kafkaは柔軟で大規模データに強いが、クラスタ管理が必要。
  - KinesisはAWSに依存し、シンプルにデータストリーミングを扱う場合に最適。

## メッセージキューとエコシステム

- Kafka内にブローカーが奇数個ある
  - 投票制なので偶数だと割れてしまうので奇数・・・何言ってるかわからない💢
- zookeeperがあるからストリーミングが発展した
  - これだけではわからない💢
- この章、なにいってるのか分からない💢
  - 意味不明、ちゃんと説明して
  - なあ、こんな意味不明なこと言って、説明した気になるなよ、金取るなカス💢
- コンシューマで、シンク側に必要な形に変換する処理やるのか？？？
  - ここで色々実装するのか？
    - それだったらここがキモだよな？

## 構築した環境の説明
- githubから落としてきたリソースを`docker compose up -d`で動かしてみる
- ４つコンテナが立ち上がる
  1. pyspark_setting pyspark
  2. pyspark_setting db_mysql 👈これは今回使わない
  3. pyspark_setting nodejs   👈これがパブリッシャー(*1)
  4. pyspark_setting kafka

(*1)